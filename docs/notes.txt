Goal:
Do edge detection on OV7670 video stream.

///////////////////////////////////////////////
Intermediate Goal 3:
-> Implement a reconfigurable kernel processor (KP) that applies
   a kernel to the greyscale video stream prior to frame buffer.

    - KP should be parameterized.
        - Users should be able to specify kernel size.
        - Users should be able to specify kernel constants.
        - Users should be able to specify the video resolution.
    
    - KP should have an enable input such that the unaltered
      video stream is passed through.

    Need to find out what the fmax of system currently is in order
    to optimize KP. 

    Higher frequency -> more pipeline stages -> higher cycles per op
                                vs 
    Lower frequency -> fewer pipeline stages -> fewer cycles per op



///////////////////////////////////////////////
Intermediate Goal 2:
-> Implement a preprocessor that converts RGB444 to grayscale
   prior to framebuffer

-> Add functionality to camera configuration module:
        - when in greyscale mode, use RGB565
        - when in color mode, use RGB444


   Grayscale Algorithm:
   - luminosity method

   y = 0.299R + 0.587G + 0.114B

Potential Approaches:

1) Use 32-bit single precision fixed-point arithmetic,
   then truncate the result for the 12-bit framebuffer.

2) Change the form of the algorithm to:
    y = (299/100)*R + (587/100)*G + (114/100)*B

3) Use bit shifts to get close to the constants.
    y = [ (R>>2) + (R>>5) + (R>>6) ] + [ (G>>1) + (G>>4) + (G>>5)] + [ (B>>3) ]
    y = [  0.25R +  0.03R +  0.01R ] + [  0.5G  + 0.06G  + 0.03G ] + [ 0.12B  ]
    y = [0.29R] + [0.59G] + [0.12B]

Selected Approach: 3)
    1) is overkill considering the result will be truncated and input is 
       only 12-bit RGB.
    2) uses divides and multiplies which are expensive in terms of 
       dsp slices and is slow.
    3) uses only shifts and adds, which is fastest and least expensive;
       however, this comes at cost of precision.

-> use matlab to find maximum error


///////////////////////////////////////////////
Intermediate Goal 1: 
-> Buffer camera video data in external memory
-> Read video data from external memory 
-> Display video data via VGA 


    1) button debounce module
        - verilog testbench

    2) VGA driver
        - formal
        - verilog testbench

    3) independent clock FIFO
        - formal
        - systemverilog testbench

    4) memory interface
        
    5) i2c module
        - formal
        
    6) system state machine
        - formal
        - systemverilog testbench

///////////////////////////////////////////////
Jots:

9/2: 
- found a bug in async fifo where the wrong inequality was used for computing
  fill level

- found a bug in async fifo where binary to graycode conversion fails for 
  wbinnext = 0x1000. Yielding 0x1800 instead of expected 0x0800. Critical bug!!
  Need to find a fix still. Highest priority.
      -> 9/3 UPDATE: stupid typo in conversion. kinda emb

- adjusted testbench to match real timings

8/31:
- implemented a self-checking testbench for the capture module. 

- found a bug in the capture module. Incorrect default statement for the FIFO write control signal
  caused consecutive writes of the same data. 

- found a bug in the memory interface. The memory interface logic reads continuously from the camera FIFO 
  unless the empty flag is asserted. There's a one-cycle delay on the read being deasserted, resulting in
  invalid data being read.
        -> the solution: implemented programmable almost-empty flag on the FIFO. The read-domain 
                         synchronized write pointer (double ff) is converted to binary and used to compute
                         a fill level, which in turn is used to control the empty flag. Did the same on the
                         write side, with a full flag.
    